{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T07:30:41.014953Z",
     "iopub.status.busy": "2025-05-11T07:30:41.014703Z",
     "iopub.status.idle": "2025-05-11T08:13:34.443699Z",
     "shell.execute_reply": "2025-05-11T08:13:34.442988Z",
     "shell.execute_reply.started": "2025-05-11T07:30:41.014933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from torch.cuda.amp import autocast\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "# ─── Config ───────────────────────────────────────────────────────────────────\n",
    "valid_path = '/kaggle/input/cleaned/valid_dataset.json'\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "# model_name = \"bert-base-uncased\"\n",
    "# model_name = \"deepset/roberta-large-squad2\"\n",
    "batch_size = 16\n",
    "max_length = 150\n",
    "stride     = 15\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─── Load dataset & tokenizer/model ───────────────────────────────────────────\n",
    "raw_valid = load_dataset(\"json\", data_files={\"validation\": valid_path})[\"validation\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModelForQuestionAnswering.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Multi-GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.eval()  # gọi sau khi bọc DataParallel\n",
    "\n",
    "# ─── Preprocessing ────────────────────────────────────────────────────────────\n",
    "def preprocess_function(examples):\n",
    "    tok = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",\n",
    "        max_length=max_length,\n",
    "        stride=stride,\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "        return_overflowing_tokens=True\n",
    "    )\n",
    "    sample_map = tok.pop(\"overflow_to_sample_mapping\")\n",
    "    offset_map = tok.pop(\"offset_mapping\")\n",
    "\n",
    "    starts, ends = [], []\n",
    "    for i, offsets in enumerate(offset_map):\n",
    "        ids = tok[\"input_ids\"][i]\n",
    "        cls_index = ids.index(tokenizer.cls_token_id)\n",
    "        seq_ids = tok.sequence_ids(i)\n",
    "        sample_idx = sample_map[i]\n",
    "        answers = examples[\"answers\"][sample_idx]\n",
    "\n",
    "        if not answers[\"answer_start\"]:\n",
    "            starts.append(cls_index); ends.append(cls_index); continue\n",
    "\n",
    "        s_char = answers[\"answer_start\"][0]\n",
    "        text   = answers[\"text\"][0]\n",
    "        e_char = s_char + len(text)\n",
    "\n",
    "        ts = next(j for j, sid in enumerate(seq_ids) if sid == 1)\n",
    "        te = len(ids) - 1\n",
    "        while seq_ids[te] != 1: te -= 1\n",
    "\n",
    "        if not (offsets[ts][0] <= s_char and offsets[te][1] >= e_char):\n",
    "            starts.append(cls_index); ends.append(cls_index)\n",
    "        else:\n",
    "            while ts < len(offsets) and offsets[ts][0] <= s_char: ts += 1\n",
    "            starts.append(ts - 1)\n",
    "            while te >= 0 and offsets[te][1] >= e_char: te -= 1\n",
    "            ends.append(te + 1)\n",
    "\n",
    "    tok[\"start_positions\"] = starts\n",
    "    tok[\"end_positions\"]   = ends\n",
    "    tok[\"offset_mapping\"]                = offset_map\n",
    "    tok[\"overflow_to_sample_mapping\"]   = sample_map\n",
    "    return tok\n",
    "\n",
    "tokenized_valid = raw_valid.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=raw_valid.column_names,\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "# ─── DataLoader ────────────────────────────────────────────────────────────────\n",
    "def collate_fn(batch):\n",
    "    tensor_keys = [\"input_ids\",\"attention_mask\",\"start_positions\",\"end_positions\"]\n",
    "    collated = {k: torch.tensor([d[k] for d in batch]) for k in tensor_keys}\n",
    "    collated[\"offset_mapping\"]             = [d[\"offset_mapping\"] for d in batch]\n",
    "    collated[\"overflow_to_sample_mapping\"] = [d[\"overflow_to_sample_mapping\"] for d in batch]\n",
    "    return collated\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    tokenized_valid, batch_size=batch_size,\n",
    "    shuffle=False, collate_fn=collate_fn, num_workers=0\n",
    ")\n",
    "\n",
    "# ─── Metric helpers ───────────────────────────────────────────────────────────\n",
    "def normalize_and_tokenize(text):\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text.lower())\n",
    "\n",
    "def compute_metrics_single(pred, truths):\n",
    "    ems = [int(pred.strip().lower() == t.strip().lower()) for t in truths]\n",
    "    EM = max(ems) if truths else 1\n",
    "    ptoks = normalize_and_tokenize(pred)\n",
    "    best_f1 = best_prec = best_rec = 0.0\n",
    "    for t in truths:\n",
    "        ttoks = normalize_and_tokenize(t)\n",
    "        common = Counter(ptoks) & Counter(ttoks)\n",
    "        n_common = sum(common.values())\n",
    "        if n_common == 0:\n",
    "            continue\n",
    "        prec = n_common / len(ptoks) if ptoks else 0\n",
    "        rec  = n_common / len(ttoks) if ttoks else 0\n",
    "        f1   = 2 * prec * rec / (prec + rec) if prec + rec > 0 else 0\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_prec, best_rec = f1, prec, rec\n",
    "    refs = [normalize_and_tokenize(t) for t in truths]\n",
    "    BLEU = sentence_bleu(refs, ptoks, weights=(0.25,0.25,0.25,0.25),\n",
    "                         smoothing_function=SmoothingFunction().method2)\n",
    "    return EM, best_f1, best_prec, best_rec, BLEU\n",
    "\n",
    "# ─── Inference & Evaluation ────────────────────────────────────────────────────\n",
    "all_EM, all_F1, all_P, all_R, all_B = [], [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader):\n",
    "        input_ids      = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        start_logits = outputs.start_logits.cpu().numpy()\n",
    "        end_logits   = outputs.end_logits.cpu().numpy()\n",
    "\n",
    "        for i in range(input_ids.size(0)):\n",
    "            sample_idx = batch[\"overflow_to_sample_mapping\"][i]\n",
    "            raw = raw_valid[sample_idx]\n",
    "            context = raw[\"context\"]\n",
    "            truths = raw[\"answers\"][\"text\"]\n",
    "\n",
    "            s_idx = np.argmax(start_logits[i])\n",
    "            e_idx = np.argmax(end_logits[i])\n",
    "            offsets = batch[\"offset_mapping\"][i]\n",
    "\n",
    "            if s_idx >= len(offsets) or e_idx >= len(offsets) or s_idx > e_idx:\n",
    "                pred = \"\"\n",
    "            else:\n",
    "                s_char, e_char = offsets[s_idx][0], offsets[e_idx][1]\n",
    "                pred = context[s_char:e_char].strip()\n",
    "\n",
    "            EM, F1, P, R, BLEU = compute_metrics_single(pred, truths)\n",
    "            all_EM.append(EM); all_F1.append(F1)\n",
    "            all_P.append(P); all_R.append(R); all_B.append(BLEU)\n",
    "\n",
    "# ─── Report ────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n QA Metrics:\")\n",
    "print(f\"Exact Match : {np.mean(all_EM):5.2f}%\")\n",
    "print(f\"F1 Score    : {np.mean(all_F1):5.2f}%\")\n",
    "print(f\"Precision   : {np.mean(all_P):5.2f}%\")\n",
    "print(f\"Recall      : {np.mean(all_R):5.2f}%\")\n",
    "print(f\"BLEU-4      : {np.mean(all_B):5.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7346783,
     "sourceId": 11704580,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
